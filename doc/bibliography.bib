@comment{https://ctan.org/tex-archive/info/bibtex/tamethebeast}

@manual{matisfundis18,
 title     = {Discrete and Continuous Data},
 author    = {Les Gates and Dianne Gentry and David Sevilla},
 url       = {https://www.mathsisfun.com/data/data-discrete-continuous.html},
 year      = {2018}
 }

@manual{matisfuncom18,
 title     = {Combinations and Permutations},
 author    = {Les Gates and Dianne Gentry and David Sevilla},
 url       = {https://www.mathsisfun.com/combinatorics/combinations-permutations.html},
 year      = {2018}
 }

@manual{yue18,
 title     = {Derivation of Exponential Distribution},
 author    = {Yue, Dick K.P.},
 url       = {https://ocw.mit.edu/courses/mechanical-engineering/2-854-introduction-to-manufacturing-systems-fall-2016/lecture-notes/derivation-of-exponential-distribution/},
 year      = {2018}
 }

@book{par99,
 title     = {Stochastic Processes},
 author    = {Emanuel Parzen},
 year      = {1999},
 publisher = {SIAM},
 annote    = {
           This introductory textbook explains how and why probability models
           are applied to scientific fields such as medicine, biology, physics,
           oceanography, economics, and psychology to solve problems about
           stochastic processes. It does not just show how a problem is solved
           but explains why by formulating questions and first steps in the
           solutions. Stochastic Processes is ideal for a course aiming to give
           examples of the wide variety of empirical phenomena for which
           stochastic processes provide mathematical models. It introduces the
           methods of probability model building and provides the reader with
           mathematically sound techniques as well as the ability to further
           study the theory of stochastic processes. Originally published in
           1962, this was the first comprehensive survey of stochastic processes
           requiring only a minimal background in introductory probability
           theory and mathematical analysis. Stochastic Processes continues to
           be unique, with many topics and examples still not discussed in other
           textbooks.}
 }

@book{ros02,
 title     = {Discrete Mathematics and Its Applications},
 author    = {Kenneth H. Rosen},
 year      = {2002},
 edition   = {7th},
 publisher = {McGraw-Hill Higher Education},
 annote    = {
           Discrete Mathematics and its Applications, Seventh Edition, is
           intended for one- or two-term introductory discrete mathematics
           courses taken by students from a wide variety of majors, including
           computer science, mathematics, and engineering. This renowned
           best-selling text, which has been used at over 500 institutions
           around the world, gives a focused introduction to the primary themes
           in a discrete mathematics course and demonstrates the relevance and
           practicality of discrete mathematics to a wide a wide variety of
           real-world applications...from computer science to data networking,
           to psychology.}
}

@book{wacmensch08,
 title     = {Mathematical Statistics with Applications},
 author    = {Wackerly, Dennis D. and Mendenhall, William and Scheaffer, Richard
              L.
             },
 year      = {2008},
 edition   = {7th},
 publisher = {Thomson Learning, Inc.},
 annote    = {
           In their bestselling MATHEMATICAL STATISTICS WITH APPLICATIONS,
           premiere authors Dennis Wackerly, William Mendenhall, and Richard L.
           Scheaffer present a solid foundation in statistical theory while
           conveying the relevance and importance of the theory in solving
           practical problems in the real world. The authors' use of practical
           applications and excellent exercises helps students discover the
           nature of statistics and understand its essential role in scientific
           research.}
}

@inproceedings{rajgraher05,
 title     = {Poisson-Networks: A Model for structured point processes},
 author    = {Rajaram, Shyamsundar and Graepel, Thore and Herbrich, Ralf},
 booktitle = {Proceedings of the Tenth International Workshop on Artificial
              Intelligence and Statistics},
 year      = {2005},
 month     = {January},
 abstract  = {
           Modelling structured multivariate point process data has wide ranging
           applications like understanding neural activity, developing faster
           file access systems and learning dependencies among servers in large
           networks. In this paper, we develop the Poisson network model for
           representing multivariate structured Poisson processes. In our model
           each node of the network represents a Poisson process. The novelty of
           our work is that waiting times of a process are modelled by an
           exponential distribution with a piecewise constant rate function that
           depends on the event counts of its parents in the network in a
           generalised linear way. Our choice of model allows to perform exact
           sampling from arbitrary structures. We adopt a Bayesian approach for
           learning the network structure. Further, we discuss fixed point and
           sampling based approximations for performing inference of rate
           functions in Poisson networks.},
 publisher = {Society for Artificial Intelligence and Statistics},
 url       = {https://www.microsoft.com/en-us/research/publication/poisson-networks-a-model-for-structured-point-processes/},
}

@inproceedings{gunmeexu11,
 title     = {A Model for Temporal Dependencies in Event Streams},
 author    = {Gunawardana, Asela and Meek, Christopher and Xu, Puyang},
 booktitle = {Neural Information Processing Systems},
 year      = {2011},
 abstract  = {
           We introduce the Piecewise-Constant Conditional Intensity Model, a
           model for learning temporal dependencies in event streams.
           We describe a closed-form Bayesian approach to learning these models,
           and describe an importance sampling algorithm for forecasting future
           events using these models, using a proposal distribution based on
           Poisson superposition. We then use synthetic data, supercomputer
           event logs, and web search query logs to illustrate that our learning
           algorithm can efficiently learn nonlinear temporal dependencies, and
           that our importance sampling algorithm can effectively forecast
           future events.},
 publisher = {Neural Information Processing Systems Foundation},
 url       = {https://www.microsoft.com/en-us/research/publication/a-model-for-temporal-dependencies-in-event-streams/}
}

@inproceedings{pargunmee12,
 title     = {Conjoint Modeling of Temporal Dependencies in Event Streams},
 author    = {Parikh, Ankur P. and Gunawardana, Asela and Meek, Chris},
 booktitle = {UAI Bayesian Modelling Applications Workshop},
 year      = {2012},
 abstract  = {
           Many real world applications depend on modeling the temporal dynamics
           of streams of diverse events, many of which are rare. We introduce a
           novel model class, Conjoint Piecewise-Constant Conditional Intensity
           Models, and a learning algorithm that together yield a data-driven
           approach to parameter sharing with the aim of better modeling such
           event streams. We empirically demonstrate that our approach yields
           more accurate models of two real world data sets: search query logs
           and data center system logs.},
 publisher = {},
 url       = {https://www.microsoft.com/en-us/research/publication/conjoint-modeling-of-temporal-dependencies-in-event-streams/}
}

@inproceedings{chihecmee97,
 title     = {A Bayesian Approach to Learning Bayesian Networks with Local
           Structure},
 author    = {Chickering, David Maxwell and Heckerman, David and Meek,
           Christopher},
 booktitle = {Proceedings of the Thirteenth Conference on Uncertainty in
           Artificial Intelligence},
 series    = {UAI'97},
 year      = {1997},
 isbn      = {1-55860-485-5},
 location  = {Providence, Rhode Island},
 pages     = {80--89},
 numpages  = {10},
 url       = {http://dl.acm.org/citation.cfm?id=2074226.2074236},
 acmid     = {2074236},
 publisher = {Morgan Kaufmann Publishers Inc.},
 address   = {San Francisco, CA, USA},
}

@article{did08,
 title     = {Graphical Models for Marked Point Processes Based on Local
              Independence},
 author    = {Didelez, Vanessa},
 abstract  = {
           A new class of graphical models capturing the dependence structure of
           events that occur in time is proposed. The graphs represent so-called
           local independences, meaning that the intensities of certain types of
           events are independent of some (but not necessarilly all) events in
           the past. This dynamic concept of independence is asymmetric, similar
           to Granger non-causality, so the corresponding local independence
           graphs differ considerably from classical graphical models. Hence a
           new notion of graph separation, which is called Î´-separation, is
           introduced and implications for the underlying model as well as for
           likelihood inference are explored. Benefits regarding facilitation of
           reasoning about and understanding of dynamic dependences as well as
           computational simplifications are discussed.},
 journal   = {Journal of the Royal Statistical Society. Series B (Statistical Methodology)},
 url       = {http://www.jstor.org/stable/20203821},
 number    = {1},
 pages     = {245--264},
 publisher = {[Royal Statistical Society, Wiley]},
 volume    = {70},
 year      = {2008}
}

@book{dalver09,
 title     = {An introduction to the theory of point processes. {V}ol. {I}},
 author    = {Daley, D. J. and Vere-Jones, D.},
 edition   = {Second},
 publisher = {Springer-Verlag},
 series    = {Probability and its Applications (New York)},
 address   = {New York},
 isbn      = {0-387-95541-0},
 year      = {2003}
}

@manual{hol18,
 title     = {Derivation of the Pfd for an Exponential Distribution},
 author    = {MathHolt},
 url       = {https://www.youtube.com/watch?v=yldSqu3WArw},
 year      = {2018}
 }